{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96c78c0-9430-4759-a756-e54d14af60fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:25.138341Z",
     "iopub.status.busy": "2025-11-27T10:54:25.137945Z",
     "iopub.status.idle": "2025-11-27T10:54:31.566111Z",
     "shell.execute_reply": "2025-11-27T10:54:31.565627Z",
     "shell.execute_reply.started": "2025-11-27T10:54:25.138312Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:albumentations.check_version:Error fetching version info\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/albumentations/check_version.py\", line 32, in fetch_version_info\n",
      "    data = response.read()\n",
      "  File \"/usr/local/lib/python3.10/http/client.py\", line 482, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"/usr/local/lib/python3.10/http/client.py\", line 631, in _safe_read\n",
      "    data = self.fp.read(amt)\n",
      "  File \"/usr/local/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/local/lib/python3.10/ssl.py\", line 1307, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/local/lib/python3.10/ssl.py\", line 1163, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åº“å¯¼å…¥å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import pydicom as dicomio \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# è®© matplotlib å›¾è¡¨ç›´æ¥åœ¨ Jupyter ä¸­æ˜¾ç¤º\n",
    "%matplotlib inline \n",
    "\n",
    "# å¯¼å…¥æœ¬åœ°æ¨¡å—\n",
    "try:\n",
    "    from loss import TverskyLoss\n",
    "    from net import UNet_2D, UNet_3D\n",
    "    from volume_patch_composer import volume_composer, patch_creator\n",
    "    from dataset import Pancreas_2D_dataset, Pancreas_3D_dataset, partitioning\n",
    "    from metrics import performance_metrics\n",
    "    from train import train_2D, train_3D\n",
    "    from inference import get_inference_performance_metrics_3D\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„æ¨¡å—æ–‡ä»¶ (å¦‚ net.py, loss.py)ã€‚\\nè¯¦ç»†ä¿¡æ¯: {e}\")\n",
    "\n",
    "print(\"åº“å¯¼å…¥å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b943f81-bd57-46d7-8043-aba9e3326a82",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:31.567449Z",
     "iopub.status.busy": "2025-11-27T10:54:31.567162Z",
     "iopub.status.idle": "2025-11-27T10:54:31.597909Z",
     "shell.execute_reply": "2025-11-27T10:54:31.597366Z",
     "shell.execute_reply.started": "2025-11-27T10:54:31.567432Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é…ç½®å·²åŠ è½½ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================\n",
    "CONFIG = {\n",
    "    'raw_ct_dir': './Pancreas-CT',              \n",
    "    'raw_label_dir': './Pancreas-CT-Label',     \n",
    "    'processed_2d_dir': './data',               \n",
    "    'processed_3d_dir': './data3D',             \n",
    "    \n",
    "    'unet_2d': False,              \n",
    "    'batch_size': 32,                \n",
    "    'num_workers': 4,               \n",
    "    'n_epochs': 200,                \n",
    "    'inference_only': False,       \n",
    "    'train_on_gpu': torch.cuda.is_available(),\n",
    "    'seed': 51\n",
    "}\n",
    "\n",
    "# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def process_ct_window(ct_array, w_level=40, w_width=400):\n",
    "    min_val = w_level - w_width / 2\n",
    "    max_val = w_level + w_width / 2\n",
    "    ct_clipped = np.clip(ct_array, min_val, max_val)\n",
    "    ct_norm = (ct_clipped - min_val) / (max_val - min_val)\n",
    "    ct_norm = ct_norm * 255.0\n",
    "    return ct_norm.astype(np.uint8)\n",
    "\n",
    "def prepare_directories():\n",
    "    for p in [CONFIG['processed_2d_dir'], CONFIG['processed_3d_dir']]:\n",
    "        if not os.path.exists(p):\n",
    "            os.makedirs(p)\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "set_seed(CONFIG['seed'])\n",
    "print(\"é…ç½®å·²åŠ è½½ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22082e8a-ed95-48f5-bfa9-987222c4632d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:31.598951Z",
     "iopub.status.busy": "2025-11-27T10:54:31.598753Z",
     "iopub.status.idle": "2025-11-27T10:54:31.609737Z",
     "shell.execute_reply": "2025-11-27T10:54:31.609287Z",
     "shell.execute_reply.started": "2025-11-27T10:54:31.598915Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_robust():\n",
    "    \"\"\"é²æ£’çš„æ•°æ®é¢„å¤„ç†å‡½æ•°\"\"\"\n",
    "    print(\"--- æ£€æŸ¥æ•°æ®çŠ¶æ€ ---\")\n",
    "    check_patient = os.path.join(CONFIG['processed_2d_dir'], 'Patient0082', 'CT')\n",
    "    if os.path.exists(check_patient) and len(os.listdir(check_patient)) > 0:\n",
    "        print(\"âœ… æ£€æµ‹åˆ°æœ¬åœ°å·²æœ‰é¢„å¤„ç†æ•°æ® (./data)ï¼Œè·³è¿‡ PNG ç”Ÿæˆæ­¥éª¤ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ”„ æœªæ‰¾åˆ°å®Œæ•´æ•°æ®ï¼Œå¼€å§‹æ‰§è¡Œé¢„å¤„ç† (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...\")\n",
    "    prepare_directories()\n",
    "\n",
    "    # æ£€æŸ¥ pydicom ç‰ˆæœ¬å…¼å®¹æ€§\n",
    "    try:\n",
    "        if not hasattr(dicomio, 'dcmread'):\n",
    "            dicomio.dcmread = dicomio.read_file\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i in range(1, 83):\n",
    "        patient_id = '{:04d}'.format(i)\n",
    "        \n",
    "        # è·¯å¾„å‡†å¤‡\n",
    "        nifti_filename = f\"label{patient_id}.nii.gz\"\n",
    "        nifti_path = os.path.join(CONFIG['raw_label_dir'], nifti_filename)\n",
    "        ct_folder_pattern = os.path.join(CONFIG['raw_ct_dir'], f\"PANCREAS_{patient_id}\", \"**\", \"*.dcm\")\n",
    "        \n",
    "        # 1. æ£€æŸ¥æºæ–‡ä»¶\n",
    "        if not os.path.exists(nifti_path):\n",
    "            # print(f\"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶\")\n",
    "            continue\n",
    "        \n",
    "        dcm_files = glob.glob(ct_folder_pattern, recursive=True)\n",
    "        if not dcm_files:\n",
    "            # print(f\"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ° DICOM æ–‡ä»¶\")\n",
    "            continue\n",
    "\n",
    "        # 2. è¯»å–å¹¶æ’åº DICOM\n",
    "        try:\n",
    "            slices = []\n",
    "            for f in dcm_files:\n",
    "                try:\n",
    "                    ds = dicomio.dcmread(f)\n",
    "\n",
    "                    # å…ˆè½¬ä¸º float é¿å…è®¡ç®—æº¢å‡º\n",
    "                    image = ds.pixel_array.astype(np.float32)\n",
    "                    \n",
    "                    # åº”ç”¨æ–œç‡å’Œæˆªè· (å¦‚æœå­˜åœ¨)\n",
    "                    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
    "                        slope = float(ds.RescaleSlope)\n",
    "                        intercept = float(ds.RescaleIntercept)\n",
    "                        image = image * slope + intercept\n",
    "\n",
    "                    # slices.append(ds)\n",
    "                    slices.append((float(ds.ImagePositionPatient[2]), image))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            if not slices:\n",
    "                continue\n",
    "\n",
    "            # æŒ‰ Z è½´ä½ç½®æ’åº\n",
    "            # slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "            slices.sort(key=lambda x: x[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] å¤„ç†å´©æºƒ: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 3. è¯»å– Mask\n",
    "        try:\n",
    "            mask_obj = nib.load(nifti_path)\n",
    "            mask_data = mask_obj.get_fdata()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] NIfTI è¯»å–å¤±è´¥: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 4. å¯¹é½å±‚æ•°\n",
    "        num_dcm = len(slices)\n",
    "        num_mask = mask_data.shape[2]\n",
    "        valid_slices = min(num_dcm, num_mask)\n",
    "        \n",
    "        if valid_slices < 10:\n",
    "            continue\n",
    "            \n",
    "        # 5. ä¿å­˜ PNG\n",
    "        save_dir_ct = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'CT')\n",
    "        save_dir_mask = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'Masks')\n",
    "        os.makedirs(save_dir_ct, exist_ok=True)\n",
    "        os.makedirs(save_dir_mask, exist_ok=True)\n",
    "\n",
    "        # ... (å‰é¢çš„ä»£ç ä¿æŒä¸å˜)\n",
    "        try:\n",
    "            for s in range(valid_slices):\n",
    "                mask_slice = mask_data[:, :, s]\n",
    "                \n",
    "                # è·å–åŸå§‹ CT æ•°æ®\n",
    "                # raw_ct_slice = slices[s].pixel_array.transpose(1, 0)\n",
    "                raw_ct_slice = slices[s][1].transpose(1, 0)\n",
    "                \n",
    "                # --- ğŸ”¥ ä¿®æ”¹å¼€å§‹ ğŸ”¥ ---\n",
    "                # 1. å¯¹ CT è¿›è¡Œçª—ä½è°ƒæ•´å’Œå½’ä¸€åŒ– (å…³é”®ä¿®å¤!)\n",
    "                processed_ct_slice = process_ct_window(raw_ct_slice, w_level=40, w_width=400)\n",
    "                \n",
    "                # 2. ç¡®ä¿ Mask ä¹Ÿæ˜¯ uint8 æ ¼å¼ (0 å’Œ 255, æˆ–è€… 0 å’Œ 1)\n",
    "                # å»ºè®®å°† Mask ä¹˜ä»¥ 255 ä»¥ä¾¿è‚‰çœ¼è§‚å¯Ÿï¼Œä½†åœ¨è¯»å–æ—¶è¦é™¤å›æ¥\n",
    "                # è¿™é‡Œä¸ºäº†å…¼å®¹ä½ ç°æœ‰çš„ dataset ä»£ç (å‡è®¾å®ƒè¯»å–0/1)ï¼Œæˆ‘ä»¬ä¿æŒ 0/1 ä½†è½¬ä¸º uint8\n",
    "                mask_slice = mask_slice.astype(np.uint8)\n",
    "                \n",
    "                # --- ğŸ”¥ ä¿®æ”¹ç»“æŸ ğŸ”¥ ---\n",
    "\n",
    "                filename = f\"{s:04d}.png\"\n",
    "                cv2.imwrite(os.path.join(save_dir_mask, filename), mask_slice)\n",
    "                cv2.imwrite(os.path.join(save_dir_ct, filename), processed_ct_slice)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] ä¿å­˜å‡ºé”™: {e}\")      \n",
    "\n",
    "    print(\"--- æ•°æ®é¢„å¤„ç†å®Œæˆ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703cd75d-3c85-4b5d-a458-851365f1377a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:31.610678Z",
     "iopub.status.busy": "2025-11-27T10:54:31.610349Z",
     "iopub.status.idle": "2025-11-27T10:54:32.152214Z",
     "shell.execute_reply": "2025-11-27T10:54:32.151691Z",
     "shell.execute_reply.started": "2025-11-27T10:54:31.610657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- æ£€æŸ¥æ•°æ®çŠ¶æ€ ---\n",
      "âœ… æ£€æµ‹åˆ°æœ¬åœ°å·²æœ‰é¢„å¤„ç†æ•°æ® (./data)ï¼Œè·³è¿‡ PNG ç”Ÿæˆæ­¥éª¤ã€‚\n",
      "æ„å»ºæ–‡ä»¶ç´¢å¼•...\n",
      "æœ‰æ•ˆç—…ä¾‹æ•°: 80\n",
      "æ£€æŸ¥ 3D æ•°æ®ç¼“å­˜...\n",
      "âœ… æ‰€æœ‰ 3D æ•°æ® (.pt) å·²å­˜åœ¨ï¼Œè·³è¿‡é‡é‡‡æ ·æ­¥éª¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. æ‰§è¡Œé¢„å¤„ç†\n",
    "preprocess_data_robust()\n",
    "\n",
    "# 2. æ„å»ºæ•°æ®ç´¢å¼•\n",
    "print(\"æ„å»ºæ–‡ä»¶ç´¢å¼•...\")\n",
    "patient_path_list = {'CT': {}, 'Masks': {}}\n",
    "patient_image_cnt_CT = {}\n",
    "patient_image_cnt_Mask = {}\n",
    "valid_patients = []\n",
    "patient_dirs = sorted(glob.glob(os.path.join(CONFIG['processed_2d_dir'], 'Patient*')))\n",
    "\n",
    "for p_dir in patient_dirs:\n",
    "    p_key = os.path.basename(p_dir)\n",
    "    ct_files = sorted(glob.glob(os.path.join(p_dir, 'CT', '*.png')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(p_dir, 'Masks', '*.png')))\n",
    "    if len(ct_files) > 0 and len(ct_files) == len(mask_files):\n",
    "        patient_path_list['CT'][p_key] = ct_files\n",
    "        patient_path_list['Masks'][p_key] = mask_files\n",
    "        patient_image_cnt_CT[p_key] = len(ct_files)\n",
    "        patient_image_cnt_Mask[p_key] = len(mask_files)\n",
    "        valid_patients.append(p_key)\n",
    "\n",
    "print(f\"æœ‰æ•ˆç—…ä¾‹æ•°: {len(valid_patients)}\")\n",
    "\n",
    "# 3. 3D æ•°æ®ç¼“å­˜\n",
    "print(\"æ£€æŸ¥ 3D æ•°æ®ç¼“å­˜...\")\n",
    "d1 = torch.linspace(-1, 1, 256)\n",
    "d2 = torch.linspace(-1, 1, 256)\n",
    "d3 = torch.linspace(-1, 1, 128)\n",
    "meshx, meshy, meshz = torch.meshgrid((d1, d2, d3), indexing='ij')\n",
    "grid = torch.stack((meshx, meshy, meshz), 3).unsqueeze(0)\n",
    "\n",
    "new_pt_count = 0\n",
    "for patient in valid_patients:\n",
    "    out_ct_path = os.path.join(CONFIG['processed_3d_dir'], patient + '_CT.pt')\n",
    "    if not os.path.exists(out_ct_path):\n",
    "        try:\n",
    "            volume_composer(patient, patient_image_cnt_CT, patient_path_list, grid)\n",
    "            new_pt_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Resizing {patient} error: {e}\")\n",
    "\n",
    "if new_pt_count == 0:\n",
    "    print(\"âœ… æ‰€æœ‰ 3D æ•°æ® (.pt) å·²å­˜åœ¨ï¼Œè·³è¿‡é‡é‡‡æ ·æ­¥éª¤ã€‚\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ æ–°ç”Ÿæˆäº† {new_pt_count} ä¸ª 3D æ•°æ®æ–‡ä»¶ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21ee6e7-d70d-4cb1-8c83-1777aec83ceb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:32.153048Z",
     "iopub.status.busy": "2025-11-27T10:54:32.152861Z",
     "iopub.status.idle": "2025-11-27T10:54:34.937717Z",
     "shell.execute_reply": "2025-11-27T10:54:34.937208Z",
     "shell.execute_reply.started": "2025-11-27T10:54:32.153030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡ Dataset...\n",
      "train:  56   valid:  7   test:  17   total:  80\n",
      "åŠ è½½ Patches (è¿™æ­¥éœ€è¦ä¸€ç‚¹å†…å­˜)...\n",
      "DataLoader å‡†å¤‡å°±ç»ªã€‚\n"
     ]
    }
   ],
   "source": [
    "# 4. è®­ç»ƒå‡†å¤‡\n",
    "print(\"å‡†å¤‡ Dataset...\")\n",
    "part = partitioning(valid_patients, split_ratio=[0.7, 0.1, 0.2])\n",
    "\n",
    "kc, kh, kw = 32, 64, 64\n",
    "dc, dh, dw = 32, 64, 64\n",
    "\n",
    "CT_patches = {}\n",
    "mask_patches = {}\n",
    "\n",
    "print(\"åŠ è½½ Patches (è¿™æ­¥éœ€è¦ä¸€ç‚¹å†…å­˜)...\")\n",
    "for p in ['train', 'valid']:\n",
    "    CT_patches[p], mask_patches[p] = patch_creator(part[p], kw, kh, kc, dw, dh, dc)\n",
    "\n",
    "dataset_train = Pancreas_3D_dataset(CT_patches['train'], mask_patches['train'], augment=True, is_train=False)\n",
    "dataset_valid = Pancreas_3D_dataset(CT_patches['valid'], mask_patches['valid'], augment=False, is_train=False)\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(dataset_train, batch_size=CONFIG['batch_size'], \n",
    "                                         shuffle=True, num_workers=CONFIG['num_workers']),\n",
    "    'valid': torch.utils.data.DataLoader(dataset_valid, batch_size=CONFIG['batch_size'], \n",
    "                                         shuffle=False, num_workers=CONFIG['num_workers'])\n",
    "}\n",
    "print(\"DataLoader å‡†å¤‡å°±ç»ªã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0cf5dc-4f55-48af-9f54-355e3bef9ae6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:34.939221Z",
     "iopub.status.busy": "2025-11-27T10:54:34.938966Z",
     "iopub.status.idle": "2025-11-27T10:54:35.837813Z",
     "shell.execute_reply": "2025-11-27T10:54:35.837193Z",
     "shell.execute_reply.started": "2025-11-27T10:54:34.939202Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹åŒ–æ¨¡å‹...\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: ./results/run_20251127-0053_model.pt\n",
      "âœ… åŠ è½½æˆåŠŸï¼å°†åœ¨ç°æœ‰åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚\n",
      "æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# 5. åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨\n",
    "print(\"åˆå§‹åŒ–æ¨¡å‹...\")\n",
    "model = UNet_3D(1, 1, 32, 0.2)\n",
    "if CONFIG['train_on_gpu']:\n",
    "    model.cuda()        \n",
    "\n",
    "# ================= å…³é”®ä¿®æ”¹ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ =================\n",
    "# âš ï¸ æ³¨æ„ï¼šè¯·ç¡®è®¤æ–‡ä»¶åæ˜¯å¦æ­£ç¡®\n",
    "checkpoint_path = './results/run_20251127-0053_model.pt' \n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {checkpoint_path}\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"âœ… åŠ è½½æˆåŠŸï¼å°†åœ¨ç°æœ‰åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒã€‚\")     \n",
    "# ========================================================\n",
    "\n",
    "# å®šä¹‰ Loss (è¿™é‡Œç”¨äº†ä½ æ–°çš„å‚æ•°)\n",
    "criterion = TverskyLoss(1e-6, 0.5, 0.5)\n",
    "# 1. å®šä¹‰åŸºç¡€ä¼˜åŒ–å™¨ (LR ä¼šè¢« Scheduler è¦†ç›–ï¼Œæ‰€ä»¥è¿™é‡Œåˆå§‹ LR å¯ä»¥éšæ„ï¼Œä½†å»ºè®®è®¾ä¸º max_lr çš„ 1/10 æˆ– 1/25)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 2.å®šä¹‰ OneCycleLR\n",
    "# max_lr: æœ€å¤§å­¦ä¹ ç‡ï¼Œå¯ä»¥å°è¯• 1e-3 æˆ– 5e-4\n",
    "# steps_per_epoch: æ¯ä¸ª epoch çš„ batch æ•°é‡\n",
    "# epochs: æ€» epoch æ•°\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=1e-3, \n",
    "    steps_per_epoch=len(loaders['train']), \n",
    "    epochs=CONFIG['n_epochs']\n",
    ")\n",
    "\n",
    "print(\"æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39721d-cb08-4639-abed-a5e3ebfe9b54",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-27T10:54:35.839281Z",
     "iopub.status.busy": "2025-11-27T10:54:35.838701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹è®­ç»ƒ: run_20251127-1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #1 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 1 \tTraining Loss: 0.5652 \tValidation Loss: 0.8236\n",
      "Specificity: 0.999150 \tSensitivity: 0.163467 \tF2_score: 0.238218 \tDSC: 0.247582\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/201 [03:01<10:03:35, 181.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #2 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/201 [05:52<9:42:02, 175.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.5649 \tValidation Loss: 0.8467\n",
      "Specificity: 0.999450 \tSensitivity: 0.126002 \tF2_score: 0.205738 \tDSC: 0.224487\n",
      "=== Epoch #3 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 3/201 [08:44<9:33:59, 173.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.5521 \tValidation Loss: 0.8433\n",
      "Specificity: 0.999413 \tSensitivity: 0.131757 \tF2_score: 0.211207 \tDSC: 0.228182\n",
      "=== Epoch #4 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 4 \tTraining Loss: 0.5758 \tValidation Loss: 0.8182\n",
      "Specificity: 0.999021 \tSensitivity: 0.178432 \tF2_score: 0.249692 \tDSC: 0.253496\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 4/201 [11:36<9:28:49, 173.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #5 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 5/201 [14:27<9:22:40, 172.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.5702 \tValidation Loss: 0.8302\n",
      "Specificity: 0.999185 \tSensitivity: 0.153091 \tF2_score: 0.229328 \tDSC: 0.241183\n",
      "=== Epoch #6 ===\n",
      "=== Training ===\n",
      "\n",
      "DEBUG: Target Max Value: 1\n",
      "âœ… Mask å€¼æ­£å¸¸ (0-1)ã€‚\n",
      "1 / 112...\n",
      "51 / 112...\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®ä¿å­˜è·¯å¾„\n",
    "results_dir = 'results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M\")\n",
    "experiment_name = f\"run_{timestamp}\"\n",
    "model_save_path = os.path.join(results_dir, f\"{experiment_name}_model.pt\")\n",
    "loss_plot_path = os.path.join(results_dir, f\"{experiment_name}_loss_curve.png\")\n",
    "metric_save_path = os.path.join(results_dir, f\"{experiment_name}_metrics.csv\")\n",
    "result_save_path = os.path.join(results_dir, f\"{experiment_name}_inference_results.csv\")\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ: {experiment_name}\")\n",
    "\n",
    "if not CONFIG['inference_only']:\n",
    "    # 3. æŠŠ scheduler ä¼ è¿›å»\n",
    "    model = train_3D(CONFIG['n_epochs'], loaders, model, optimizer, criterion, \n",
    "                     CONFIG['train_on_gpu'], performance_metrics, model_save_path, 0.5, \n",
    "                     scheduler=scheduler) # ä¼ å…¥ scheduler\n",
    "    \n",
    "    # è®­ç»ƒç»“æŸåå¤„ç†æ•°æ®\n",
    "    if os.path.exists('performance_metrics.csv'):\n",
    "        df = pd.read_csv('performance_metrics.csv')\n",
    "        df.to_csv(metric_save_path, index=False)\n",
    "        \n",
    "        # ç›´æ¥åœ¨ Jupyter ä¸­ç”»å›¾\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df['epoch'], df['Training Loss'], label='Train')\n",
    "        plt.plot(df['epoch'], df['Validation Loss'], label='Valid')\n",
    "        plt.legend()\n",
    "        plt.title(f'Training Process ({experiment_name})')\n",
    "        plt.show() # ç›´æ¥æ˜¾ç¤º\n",
    "        \n",
    "        plt.savefig(loss_plot_path)\n",
    "        print(\"è®­ç»ƒå®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb68c7-72dd-45e6-bc2e-38d955ee43a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- å¼€å§‹æµ‹è¯•é›†è¯„ä¼° ---\")\n",
    "# åŠ è½½åˆšåˆšè®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨æŒ‡å®šå…¶ä»–è·¯å¾„ï¼‰\n",
    "best_model_path = model_save_path \n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"åŠ è½½æ¨¡å‹æƒé‡: {best_model_path}...\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"æ­£åœ¨æµ‹è¯• {len(part['test'])} ä¸ªæµ‹è¯•é›†ç—…ä¾‹...\")\n",
    "    df_test = get_inference_performance_metrics_3D(model, part['test'], Pancreas_3D_dataset, \n",
    "                                                  CONFIG['batch_size'], CONFIG['train_on_gpu'], \n",
    "                                                  0.5, kw, kh, kc, dw, dh, dc)\n",
    "    print(\"\\nğŸ“Š æµ‹è¯•é›†ç»“æœç»Ÿè®¡:\")\n",
    "    display(df_test.describe()) # Jupyter ç‰¹æœ‰çš„æ¼‚äº®è¡¨æ ¼æ˜¾ç¤º\n",
    "    \n",
    "    df_test.to_csv(result_save_path, index=False)\n",
    "    print(f\"âœ… è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_save_path}\")\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
