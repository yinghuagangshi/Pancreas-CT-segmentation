import os
import sys
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import random
import shutil
import nibabel as nib
import pydicom as dicomio  # pydicom åº“

import torch
import torch.optim as optim

# å°è¯•å¯¼å…¥è¾…åŠ©æ¨¡å—
try:
    from loss import TverskyLoss
    from net import UNet_2D, UNet_3D
    from volume_patch_composer import volume_composer, patch_creator
    from dataset import Pancreas_2D_dataset, Pancreas_3D_dataset, partitioning
    from metrics import performance_metrics
    from train import train_2D, train_3D
    from inference import (get_inference_performance_metrics_3D)
except ImportError as e:
    print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„æ¨¡å—æ–‡ä»¶ã€‚\nè¯¦ç»†ä¿¡æ¯: {e}")
    sys.exit(1)

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
CONFIG = {
    'raw_ct_dir': './Pancreas-CT',              
    'raw_label_dir': './Pancreas-CT-Label',     
    'processed_2d_dir': './data',               
    'processed_3d_dir': './data3D',             
    
    'unet_2d': False,              
    'batch_size': 2,               
    'num_workers': 0,              
    'n_epochs': 1,                 
    'inference_only': False,       
    'train_on_gpu': torch.cuda.is_available(),
    'seed': 51
}

# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================

def set_seed(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = True

def prepare_directories():
    for p in [CONFIG['processed_2d_dir'], CONFIG['processed_3d_dir']]:
        if not os.path.exists(p):
            os.makedirs(p)

def preprocess_data_robust():
    """
    é²æ£’çš„æ•°æ®é¢„å¤„ç†å‡½æ•° (v4 - æ™ºèƒ½ç¼“å­˜ç‰ˆ)ï¼š
    å¦‚æœæ£€æµ‹åˆ°æ•°æ®å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡è€—æ—¶çš„ç”Ÿæˆæ­¥éª¤ã€‚
    """
    print("--- æ£€æŸ¥æ•°æ®çŠ¶æ€ ---")
    
    # ğŸš€ ä¼˜åŒ–ç‚¹ 1ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®ï¼Œæœ‰åˆ™è·³è¿‡
    # æ£€æŸ¥æœ€åä¸€ä¸ªç—…äººæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
    check_patient = os.path.join(CONFIG['processed_2d_dir'], 'Patient0082', 'CT')
    if os.path.exists(check_patient) and len(os.listdir(check_patient)) > 0:
        print("âœ… æ£€æµ‹åˆ°æœ¬åœ°å·²æœ‰é¢„å¤„ç†æ•°æ® (./data)ï¼Œè·³è¿‡ PNG ç”Ÿæˆæ­¥éª¤ã€‚")
        return

    print("ğŸ”„ æœªæ‰¾åˆ°å®Œæ•´æ•°æ®ï¼Œå¼€å§‹æ‰§è¡Œé¢„å¤„ç† (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    prepare_directories()

    # æ£€æŸ¥ pydicom ç‰ˆæœ¬å…¼å®¹æ€§
    try:
        if not hasattr(dicomio, 'dcmread'):
            dicomio.dcmread = dicomio.read_file
    except:
        pass

    for i in range(1, 83):
        patient_id = '{:04d}'.format(i)
        
        # è·¯å¾„å‡†å¤‡
        nifti_filename = f"label{patient_id}.nii.gz"
        nifti_path = os.path.join(CONFIG['raw_label_dir'], nifti_filename)
        ct_folder_pattern = os.path.join(CONFIG['raw_ct_dir'], f"PANCREAS_{patient_id}", "**", "*.dcm")
        
        # 1. æ£€æŸ¥æºæ–‡ä»¶
        if not os.path.exists(nifti_path):
            # print(f"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶")
            continue
        
        dcm_files = glob.glob(ct_folder_pattern, recursive=True)
        if not dcm_files:
            # print(f"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ° DICOM æ–‡ä»¶")
            continue

        # 2. è¯»å–å¹¶æ’åº DICOM
        try:
            slices = []
            for f in dcm_files:
                try:
                    ds = dicomio.dcmread(f)
                    slices.append(ds)
                except Exception:
                    pass
            
            if not slices:
                continue

            # æŒ‰ Z è½´ä½ç½®æ’åº
            slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))
            
        except Exception as e:
            print(f"âŒ [Patient {patient_id}] å¤„ç†å´©æºƒ: {e}")
            continue

        # 3. è¯»å– Mask
        try:
            mask_obj = nib.load(nifti_path)
            mask_data = mask_obj.get_fdata()
        except Exception as e:
            print(f"âŒ [Patient {patient_id}] NIfTI è¯»å–å¤±è´¥: {e}")
            continue

        # 4. å¯¹é½å±‚æ•°
        num_dcm = len(slices)
        num_mask = mask_data.shape[2]
        valid_slices = min(num_dcm, num_mask)
        
        if valid_slices < 10:
            continue
            
        # 5. ä¿å­˜ PNG
        save_dir_ct = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'CT')
        save_dir_mask = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'Masks')
        os.makedirs(save_dir_ct, exist_ok=True)
        os.makedirs(save_dir_mask, exist_ok=True)

        try:
            for s in range(valid_slices):
                mask_slice = mask_data[:, :, s]
                ct_slice = slices[s].pixel_array.transpose(1, 0) 
                filename = f"{s:04d}.png"
                cv2.imwrite(os.path.join(save_dir_mask, filename), mask_slice)
                cv2.imwrite(os.path.join(save_dir_ct, filename), ct_slice)
            
            # print(f"âœ… [Patient {patient_id}] å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ [Patient {patient_id}] ä¿å­˜å‡ºé”™: {e}")

    print("--- æ•°æ®é¢„å¤„ç†å®Œæˆ ---")

def main():
    set_seed(CONFIG['seed'])
    
    print(f"CUDA æ˜¯å¦å¯ç”¨: {CONFIG['train_on_gpu']}")
    if CONFIG['train_on_gpu']:
        print(f"ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name(0)}")

    # 1. æ™ºèƒ½é¢„å¤„ç†
    preprocess_data_robust()

    # 2. æ„å»ºæ•°æ®ç´¢å¼•
    print("æ„å»ºæ–‡ä»¶ç´¢å¼•...")
    patient_path_list = {'CT': {}, 'Masks': {}}
    patient_image_cnt_CT = {}
    patient_image_cnt_Mask = {}

    valid_patients = []
    patient_dirs = sorted(glob.glob(os.path.join(CONFIG['processed_2d_dir'], 'Patient*')))
    
    for p_dir in patient_dirs:
        p_key = os.path.basename(p_dir)
        ct_files = sorted(glob.glob(os.path.join(p_dir, 'CT', '*.png')))
        mask_files = sorted(glob.glob(os.path.join(p_dir, 'Masks', '*.png')))
        
        if len(ct_files) > 0 and len(ct_files) == len(mask_files):
            patient_path_list['CT'][p_key] = ct_files
            patient_path_list['Masks'][p_key] = mask_files
            patient_image_cnt_CT[p_key] = len(ct_files)
            patient_image_cnt_Mask[p_key] = len(mask_files)
            valid_patients.append(p_key)

    print(f"æœ‰æ•ˆç—…ä¾‹æ•°: {len(valid_patients)}")
    if len(valid_patients) == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆç—…ä¾‹ã€‚è¯·æ£€æŸ¥æ•°æ®ã€‚")
        return

    # 3. ä½“ç§¯é‡é‡‡æ · (æ™ºèƒ½è·³è¿‡)
    print("æ£€æŸ¥ 3D æ•°æ®ç¼“å­˜...")
    d1 = torch.linspace(-1, 1, 256)
    d2 = torch.linspace(-1, 1, 256)
    d3 = torch.linspace(-1, 1, 128)
    meshx, meshy, meshz = torch.meshgrid((d1, d2, d3), indexing='ij')
    grid = torch.stack((meshx, meshy, meshz), 3).unsqueeze(0)

    # ğŸš€ ä¼˜åŒ–ç‚¹ 2ï¼šå¦‚æœ .pt æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡ç”Ÿæˆ
    new_pt_count = 0
    for patient in valid_patients:
        out_ct_path = os.path.join(CONFIG['processed_3d_dir'], patient + '_CT.pt')
        if not os.path.exists(out_ct_path):
            try:
                # åªæœ‰æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰è°ƒç”¨
                volume_composer(patient, patient_image_cnt_CT, patient_path_list, grid)
                new_pt_count += 1
            except Exception as e:
                print(f"Resizing {patient} error: {e}")
    
    if new_pt_count == 0:
        print("âœ… æ‰€æœ‰ 3D æ•°æ® (.pt) å·²å­˜åœ¨ï¼Œè·³è¿‡é‡é‡‡æ ·æ­¥éª¤ã€‚")
    else:
        print(f"ğŸ”„ æ–°ç”Ÿæˆäº† {new_pt_count} ä¸ª 3D æ•°æ®æ–‡ä»¶ã€‚")

    # 4. è®­ç»ƒå‡†å¤‡
    print("å‡†å¤‡ Dataset...")
    part = partitioning(valid_patients, split_ratio=[0.7, 0.1, 0.2])
    
    kc, kh, kw = 32, 64, 64
    dc, dh, dw = 32, 64, 64

    CT_patches = {}
    mask_patches = {}
    
    print("åŠ è½½ Patches (è¿™æ­¥éœ€è¦ä¸€ç‚¹å†…å­˜)...")
    for p in ['train', 'valid']:
        CT_patches[p], mask_patches[p] = patch_creator(part[p], kw, kh, kc, dw, dh, dc)

    dataset_train = Pancreas_3D_dataset(CT_patches['train'], mask_patches['train'], augment=True)
    dataset_valid = Pancreas_3D_dataset(CT_patches['valid'], mask_patches['valid'], augment=False)

    loaders = {
        'train': torch.utils.data.DataLoader(dataset_train, batch_size=CONFIG['batch_size'], 
                                             shuffle=True, num_workers=CONFIG['num_workers']),
        'valid': torch.utils.data.DataLoader(dataset_valid, batch_size=CONFIG['batch_size'], 
                                             shuffle=False, num_workers=CONFIG['num_workers'])
    }

    # 5. æ¨¡å‹è®­ç»ƒ
    print("åˆå§‹åŒ–æ¨¡å‹...")
    model = UNet_3D(1, 1, 32, 0.2)
    if CONFIG['train_on_gpu']:
        model.cuda()

    criterion = TverskyLoss(1e-8, 0.3, 0.7)
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    
    if len(loaders['train']) == 0:
        print("âŒ è®­ç»ƒé›†ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒã€‚")
        return

    if not CONFIG['inference_only']:
        print(f"å¼€å§‹è®­ç»ƒ...")
        model = train_3D(CONFIG['n_epochs'], loaders, model, optimizer, criterion, 
                         CONFIG['train_on_gpu'], performance_metrics, 'model.pt', 0.5)

    print("è„šæœ¬è¿è¡Œç»“æŸã€‚")

if __name__ == '__main__':
    main()