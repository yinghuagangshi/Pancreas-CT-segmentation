{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c78c0-9430-4759-a756-e54d14af60fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-26T16:19:35.838660Z",
     "iopub.status.idle": "2025-11-26T16:19:35.838915Z",
     "shell.execute_reply": "2025-11-26T16:19:35.838806Z",
     "shell.execute_reply.started": "2025-11-26T16:19:35.838797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import pydicom as dicomio \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# è®© matplotlib å›¾è¡¨ç›´æ¥åœ¨ Jupyter ä¸­æ˜¾ç¤º\n",
    "%matplotlib inline \n",
    "\n",
    "# å¯¼å…¥æœ¬åœ°æ¨¡å—\n",
    "try:\n",
    "    from loss import TverskyLoss\n",
    "    from net import UNet_2D, UNet_3D\n",
    "    from volume_patch_composer import volume_composer, patch_creator\n",
    "    from dataset import Pancreas_2D_dataset, Pancreas_3D_dataset, partitioning\n",
    "    from metrics import performance_metrics\n",
    "    from train import train_2D, train_3D\n",
    "    from inference import get_inference_performance_metrics_3D\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„æ¨¡å—æ–‡ä»¶ (å¦‚ net.py, loss.py)ã€‚\\nè¯¦ç»†ä¿¡æ¯: {e}\")\n",
    "\n",
    "print(\"åº“å¯¼å…¥å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b943f81-bd57-46d7-8043-aba9e3326a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:54:15.220475Z",
     "iopub.status.busy": "2025-11-26T14:54:15.220002Z",
     "iopub.status.idle": "2025-11-26T14:54:15.259332Z",
     "shell.execute_reply": "2025-11-26T14:54:15.258824Z",
     "shell.execute_reply.started": "2025-11-26T14:54:15.220455Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é…ç½®å·²åŠ è½½ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================\n",
    "CONFIG = {\n",
    "    'raw_ct_dir': './Pancreas-CT',              \n",
    "    'raw_label_dir': './Pancreas-CT-Label',     \n",
    "    'processed_2d_dir': './data',               \n",
    "    'processed_3d_dir': './data3D',             \n",
    "    \n",
    "    'unet_2d': False,              \n",
    "    'batch_size': 32,                \n",
    "    'num_workers': 4,               \n",
    "    'n_epochs': 50,                \n",
    "    'inference_only': False,       \n",
    "    'train_on_gpu': torch.cuda.is_available(),\n",
    "    'seed': 51\n",
    "}\n",
    "\n",
    "# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def process_ct_window(ct_array, w_level=40, w_width=400):\n",
    "    min_val = w_level - w_width / 2\n",
    "    max_val = w_level + w_width / 2\n",
    "    ct_clipped = np.clip(ct_array, min_val, max_val)\n",
    "    ct_norm = (ct_clipped - min_val) / (max_val - min_val)\n",
    "    ct_norm = ct_norm * 255.0\n",
    "    return ct_norm.astype(np.uint8)\n",
    "\n",
    "def prepare_directories():\n",
    "    for p in [CONFIG['processed_2d_dir'], CONFIG['processed_3d_dir']]:\n",
    "        if not os.path.exists(p):\n",
    "            os.makedirs(p)\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "set_seed(CONFIG['seed'])\n",
    "print(\"é…ç½®å·²åŠ è½½ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22082e8a-ed95-48f5-bfa9-987222c4632d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-26T14:58:46.754135Z",
     "iopub.status.busy": "2025-11-26T14:58:46.753895Z",
     "iopub.status.idle": "2025-11-26T14:58:46.763907Z",
     "shell.execute_reply": "2025-11-26T14:58:46.763405Z",
     "shell.execute_reply.started": "2025-11-26T14:58:46.754117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data_robust():\n",
    "    \"\"\"é²æ£’çš„æ•°æ®é¢„å¤„ç†å‡½æ•°\"\"\"\n",
    "    print(\"--- æ£€æŸ¥æ•°æ®çŠ¶æ€ ---\")\n",
    "    check_patient = os.path.join(CONFIG['processed_2d_dir'], 'Patient0082', 'CT')\n",
    "    if os.path.exists(check_patient) and len(os.listdir(check_patient)) > 0:\n",
    "        print(\"âœ… æ£€æµ‹åˆ°æœ¬åœ°å·²æœ‰é¢„å¤„ç†æ•°æ® (./data)ï¼Œè·³è¿‡ PNG ç”Ÿæˆæ­¥éª¤ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ”„ æœªæ‰¾åˆ°å®Œæ•´æ•°æ®ï¼Œå¼€å§‹æ‰§è¡Œé¢„å¤„ç† (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...\")\n",
    "    prepare_directories()\n",
    "\n",
    "    # æ£€æŸ¥ pydicom ç‰ˆæœ¬å…¼å®¹æ€§\n",
    "    try:\n",
    "        if not hasattr(dicomio, 'dcmread'):\n",
    "            dicomio.dcmread = dicomio.read_file\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i in range(1, 83):\n",
    "        patient_id = '{:04d}'.format(i)\n",
    "        \n",
    "        # è·¯å¾„å‡†å¤‡\n",
    "        nifti_filename = f\"label{patient_id}.nii.gz\"\n",
    "        nifti_path = os.path.join(CONFIG['raw_label_dir'], nifti_filename)\n",
    "        ct_folder_pattern = os.path.join(CONFIG['raw_ct_dir'], f\"PANCREAS_{patient_id}\", \"**\", \"*.dcm\")\n",
    "        \n",
    "        # 1. æ£€æŸ¥æºæ–‡ä»¶\n",
    "        if not os.path.exists(nifti_path):\n",
    "            # print(f\"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶\")\n",
    "            continue\n",
    "        \n",
    "        dcm_files = glob.glob(ct_folder_pattern, recursive=True)\n",
    "        if not dcm_files:\n",
    "            # print(f\"âš ï¸  [Patient {patient_id}] è·³è¿‡: æ‰¾ä¸åˆ° DICOM æ–‡ä»¶\")\n",
    "            continue\n",
    "\n",
    "        # 2. è¯»å–å¹¶æ’åº DICOM\n",
    "        try:\n",
    "            slices = []\n",
    "            for f in dcm_files:\n",
    "                try:\n",
    "                    ds = dicomio.dcmread(f)\n",
    "\n",
    "                    # å…ˆè½¬ä¸º float é¿å…è®¡ç®—æº¢å‡º\n",
    "                    image = ds.pixel_array.astype(np.float32)\n",
    "                    \n",
    "                    # åº”ç”¨æ–œç‡å’Œæˆªè· (å¦‚æœå­˜åœ¨)\n",
    "                    if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
    "                        slope = float(ds.RescaleSlope)\n",
    "                        intercept = float(ds.RescaleIntercept)\n",
    "                        image = image * slope + intercept\n",
    "\n",
    "                    # slices.append(ds)\n",
    "                    slices.append((float(ds.ImagePositionPatient[2]), image))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            if not slices:\n",
    "                continue\n",
    "\n",
    "            # æŒ‰ Z è½´ä½ç½®æ’åº\n",
    "            # slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "            slices.sort(key=lambda x: x[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] å¤„ç†å´©æºƒ: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 3. è¯»å– Mask\n",
    "        try:\n",
    "            mask_obj = nib.load(nifti_path)\n",
    "            mask_data = mask_obj.get_fdata()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] NIfTI è¯»å–å¤±è´¥: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 4. å¯¹é½å±‚æ•°\n",
    "        num_dcm = len(slices)\n",
    "        num_mask = mask_data.shape[2]\n",
    "        valid_slices = min(num_dcm, num_mask)\n",
    "        \n",
    "        if valid_slices < 10:\n",
    "            continue\n",
    "            \n",
    "        # 5. ä¿å­˜ PNG\n",
    "        save_dir_ct = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'CT')\n",
    "        save_dir_mask = os.path.join(CONFIG['processed_2d_dir'], 'Patient' + patient_id, 'Masks')\n",
    "        os.makedirs(save_dir_ct, exist_ok=True)\n",
    "        os.makedirs(save_dir_mask, exist_ok=True)\n",
    "\n",
    "        # ... (å‰é¢çš„ä»£ç ä¿æŒä¸å˜)\n",
    "        try:\n",
    "            for s in range(valid_slices):\n",
    "                mask_slice = mask_data[:, :, s]\n",
    "                \n",
    "                # è·å–åŸå§‹ CT æ•°æ®\n",
    "                # raw_ct_slice = slices[s].pixel_array.transpose(1, 0)\n",
    "                raw_ct_slice = slices[s][1].transpose(1, 0)\n",
    "                \n",
    "                # --- ğŸ”¥ ä¿®æ”¹å¼€å§‹ ğŸ”¥ ---\n",
    "                # 1. å¯¹ CT è¿›è¡Œçª—ä½è°ƒæ•´å’Œå½’ä¸€åŒ– (å…³é”®ä¿®å¤!)\n",
    "                processed_ct_slice = process_ct_window(raw_ct_slice, w_level=40, w_width=400)\n",
    "                \n",
    "                # 2. ç¡®ä¿ Mask ä¹Ÿæ˜¯ uint8 æ ¼å¼ (0 å’Œ 255, æˆ–è€… 0 å’Œ 1)\n",
    "                # å»ºè®®å°† Mask ä¹˜ä»¥ 255 ä»¥ä¾¿è‚‰çœ¼è§‚å¯Ÿï¼Œä½†åœ¨è¯»å–æ—¶è¦é™¤å›æ¥\n",
    "                # è¿™é‡Œä¸ºäº†å…¼å®¹ä½ ç°æœ‰çš„ dataset ä»£ç (å‡è®¾å®ƒè¯»å–0/1)ï¼Œæˆ‘ä»¬ä¿æŒ 0/1 ä½†è½¬ä¸º uint8\n",
    "                mask_slice = mask_slice.astype(np.uint8)\n",
    "                \n",
    "                # --- ğŸ”¥ ä¿®æ”¹ç»“æŸ ğŸ”¥ ---\n",
    "\n",
    "                filename = f\"{s:04d}.png\"\n",
    "                cv2.imwrite(os.path.join(save_dir_mask, filename), mask_slice)\n",
    "                cv2.imwrite(os.path.join(save_dir_ct, filename), processed_ct_slice)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ [Patient {patient_id}] ä¿å­˜å‡ºé”™: {e}\")      \n",
    "\n",
    "    print(\"--- æ•°æ®é¢„å¤„ç†å®Œæˆ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703cd75d-3c85-4b5d-a458-851365f1377a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:58:51.698767Z",
     "iopub.status.busy": "2025-11-26T14:58:51.698119Z",
     "iopub.status.idle": "2025-11-26T14:58:52.117436Z",
     "shell.execute_reply": "2025-11-26T14:58:52.116862Z",
     "shell.execute_reply.started": "2025-11-26T14:58:51.698733Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- æ£€æŸ¥æ•°æ®çŠ¶æ€ ---\n",
      "âœ… æ£€æµ‹åˆ°æœ¬åœ°å·²æœ‰é¢„å¤„ç†æ•°æ® (./data)ï¼Œè·³è¿‡ PNG ç”Ÿæˆæ­¥éª¤ã€‚\n",
      "æ„å»ºæ–‡ä»¶ç´¢å¼•...\n",
      "æœ‰æ•ˆç—…ä¾‹æ•°: 80\n",
      "æ£€æŸ¥ 3D æ•°æ®ç¼“å­˜...\n",
      "âœ… æ‰€æœ‰ 3D æ•°æ® (.pt) å·²å­˜åœ¨ï¼Œè·³è¿‡é‡é‡‡æ ·æ­¥éª¤ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. æ‰§è¡Œé¢„å¤„ç†\n",
    "preprocess_data_robust()\n",
    "\n",
    "# 2. æ„å»ºæ•°æ®ç´¢å¼•\n",
    "print(\"æ„å»ºæ–‡ä»¶ç´¢å¼•...\")\n",
    "patient_path_list = {'CT': {}, 'Masks': {}}\n",
    "patient_image_cnt_CT = {}\n",
    "patient_image_cnt_Mask = {}\n",
    "valid_patients = []\n",
    "patient_dirs = sorted(glob.glob(os.path.join(CONFIG['processed_2d_dir'], 'Patient*')))\n",
    "\n",
    "for p_dir in patient_dirs:\n",
    "    p_key = os.path.basename(p_dir)\n",
    "    ct_files = sorted(glob.glob(os.path.join(p_dir, 'CT', '*.png')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(p_dir, 'Masks', '*.png')))\n",
    "    if len(ct_files) > 0 and len(ct_files) == len(mask_files):\n",
    "        patient_path_list['CT'][p_key] = ct_files\n",
    "        patient_path_list['Masks'][p_key] = mask_files\n",
    "        patient_image_cnt_CT[p_key] = len(ct_files)\n",
    "        patient_image_cnt_Mask[p_key] = len(mask_files)\n",
    "        valid_patients.append(p_key)\n",
    "\n",
    "print(f\"æœ‰æ•ˆç—…ä¾‹æ•°: {len(valid_patients)}\")\n",
    "\n",
    "# 3. 3D æ•°æ®ç¼“å­˜\n",
    "print(\"æ£€æŸ¥ 3D æ•°æ®ç¼“å­˜...\")\n",
    "d1 = torch.linspace(-1, 1, 256)\n",
    "d2 = torch.linspace(-1, 1, 256)\n",
    "d3 = torch.linspace(-1, 1, 128)\n",
    "meshx, meshy, meshz = torch.meshgrid((d1, d2, d3), indexing='ij')\n",
    "grid = torch.stack((meshx, meshy, meshz), 3).unsqueeze(0)\n",
    "\n",
    "new_pt_count = 0\n",
    "for patient in valid_patients:\n",
    "    out_ct_path = os.path.join(CONFIG['processed_3d_dir'], patient + '_CT.pt')\n",
    "    if not os.path.exists(out_ct_path):\n",
    "        try:\n",
    "            volume_composer(patient, patient_image_cnt_CT, patient_path_list, grid)\n",
    "            new_pt_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Resizing {patient} error: {e}\")\n",
    "\n",
    "if new_pt_count == 0:\n",
    "    print(\"âœ… æ‰€æœ‰ 3D æ•°æ® (.pt) å·²å­˜åœ¨ï¼Œè·³è¿‡é‡é‡‡æ ·æ­¥éª¤ã€‚\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ æ–°ç”Ÿæˆäº† {new_pt_count} ä¸ª 3D æ•°æ®æ–‡ä»¶ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21ee6e7-d70d-4cb1-8c83-1777aec83ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:58:59.868255Z",
     "iopub.status.busy": "2025-11-26T14:58:59.867908Z",
     "iopub.status.idle": "2025-11-26T14:59:28.062062Z",
     "shell.execute_reply": "2025-11-26T14:59:28.061434Z",
     "shell.execute_reply.started": "2025-11-26T14:58:59.868231Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡ Dataset...\n",
      "train:  56   valid:  7   test:  17   total:  80\n",
      "åŠ è½½ Patches (è¿™æ­¥éœ€è¦ä¸€ç‚¹å†…å­˜)...\n",
      "DataLoader å‡†å¤‡å°±ç»ªã€‚\n"
     ]
    }
   ],
   "source": [
    "# 4. è®­ç»ƒå‡†å¤‡\n",
    "print(\"å‡†å¤‡ Dataset...\")\n",
    "part = partitioning(valid_patients, split_ratio=[0.7, 0.1, 0.2])\n",
    "\n",
    "kc, kh, kw = 32, 64, 64\n",
    "dc, dh, dw = 32, 64, 64\n",
    "\n",
    "CT_patches = {}\n",
    "mask_patches = {}\n",
    "\n",
    "print(\"åŠ è½½ Patches (è¿™æ­¥éœ€è¦ä¸€ç‚¹å†…å­˜)...\")\n",
    "for p in ['train', 'valid']:\n",
    "    CT_patches[p], mask_patches[p] = patch_creator(part[p], kw, kh, kc, dw, dh, dc)\n",
    "\n",
    "dataset_train = Pancreas_3D_dataset(CT_patches['train'], mask_patches['train'], augment=True)\n",
    "dataset_valid = Pancreas_3D_dataset(CT_patches['valid'], mask_patches['valid'], augment=False)\n",
    "\n",
    "loaders = {\n",
    "    'train': torch.utils.data.DataLoader(dataset_train, batch_size=CONFIG['batch_size'], \n",
    "                                         shuffle=True, num_workers=CONFIG['num_workers']),\n",
    "    'valid': torch.utils.data.DataLoader(dataset_valid, batch_size=CONFIG['batch_size'], \n",
    "                                         shuffle=False, num_workers=CONFIG['num_workers'])\n",
    "}\n",
    "print(\"DataLoader å‡†å¤‡å°±ç»ªã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0cf5dc-4f55-48af-9f54-355e3bef9ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:59:36.868163Z",
     "iopub.status.busy": "2025-11-26T14:59:36.867845Z",
     "iopub.status.idle": "2025-11-26T14:59:38.747119Z",
     "shell.execute_reply": "2025-11-26T14:59:38.746634Z",
     "shell.execute_reply.started": "2025-11-26T14:59:36.868144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹åŒ–æ¨¡å‹...\n",
      "ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: ./results/run_20251126-1659_model.pt\n",
      "âœ… åŠ è½½æˆåŠŸï¼å°†åœ¨ç°æœ‰åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚\n",
      "æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# 5. åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨\n",
    "print(\"åˆå§‹åŒ–æ¨¡å‹...\")\n",
    "model = UNet_3D(1, 1, 32, 0.2)\n",
    "if CONFIG['train_on_gpu']:\n",
    "    model.cuda()        \n",
    "\n",
    "# ================= å…³é”®ä¿®æ”¹ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ =================\n",
    "# âš ï¸ æ³¨æ„ï¼šè¯·ç¡®è®¤æ–‡ä»¶åæ˜¯å¦æ­£ç¡®\n",
    "checkpoint_path = './results/run_20251126-1659_model.pt' \n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {checkpoint_path}\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"âœ… åŠ è½½æˆåŠŸï¼å°†åœ¨ç°æœ‰åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒã€‚\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒã€‚\")     \n",
    "# ========================================================\n",
    "\n",
    "# å®šä¹‰ Loss (è¿™é‡Œç”¨äº†ä½ æ–°çš„å‚æ•°)\n",
    "criterion = TverskyLoss(1e-6, 0.7, 0.3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "print(\"æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39721d-cb08-4639-abed-a5e3ebfe9b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:59:42.673771Z",
     "iopub.status.busy": "2025-11-26T14:59:42.673282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹è®­ç»ƒ: run_20251126-2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #1 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 1 \tTraining Loss: 0.6995 \tValidation Loss: 0.7760\n",
      "Specificity: 0.996295 \tSensitivity: 0.335803 \tF2_score: 0.251091 \tDSC: 0.190064\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1/51 [03:02<2:32:26, 182.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #2 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2/51 [05:54<2:24:08, 176.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.6791 \tValidation Loss: 0.8294\n",
      "Specificity: 0.997059 \tSensitivity: 0.241044 \tF2_score: 0.188070 \tDSC: 0.147508\n",
      "=== Epoch #3 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 3 \tTraining Loss: 0.6701 \tValidation Loss: 0.7876\n",
      "Specificity: 0.997828 \tSensitivity: 0.274585 \tF2_score: 0.299774 \tDSC: 0.261958\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 3/51 [08:48<2:19:57, 174.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #4 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4/51 [11:39<2:15:57, 173.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.6799 \tValidation Loss: 0.8242\n",
      "Specificity: 0.997461 \tSensitivity: 0.241454 \tF2_score: 0.192383 \tDSC: 0.154103\n",
      "=== Epoch #5 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 5/51 [14:30<2:12:19, 172.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.6887 \tValidation Loss: 0.7973\n",
      "Specificity: 0.997269 \tSensitivity: 0.273101 \tF2_score: 0.291441 \tDSC: 0.252522\n",
      "=== Epoch #6 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 6/51 [17:22<2:09:16, 172.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.6648 \tValidation Loss: 0.7784\n",
      "Specificity: 0.997670 \tSensitivity: 0.280730 \tF2_score: 0.236359 \tDSC: 0.206097\n",
      "=== Epoch #7 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 7/51 [20:14<2:06:28, 172.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.6401 \tValidation Loss: 0.8419\n",
      "Specificity: 0.999144 \tSensitivity: 0.158866 \tF2_score: 0.229355 \tDSC: 0.232677\n",
      "=== Epoch #8 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 8/51 [23:05<2:03:07, 171.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 0.6718 \tValidation Loss: 0.7819\n",
      "Specificity: 0.997973 \tSensitivity: 0.272212 \tF2_score: 0.231757 \tDSC: 0.201873\n",
      "=== Epoch #9 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 9/51 [25:55<1:59:51, 171.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 0.6543 \tValidation Loss: 0.7989\n",
      "Specificity: 0.998525 \tSensitivity: 0.222052 \tF2_score: 0.206759 \tDSC: 0.195471\n",
      "=== Epoch #10 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 10 \tTraining Loss: 0.5831 \tValidation Loss: 0.7872\n",
      "Specificity: 0.997989 \tSensitivity: 0.262760 \tF2_score: 0.298017 \tDSC: 0.264969\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 10/51 [28:46<1:57:03, 171.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #11 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 11/51 [31:38<1:54:20, 171.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.6284 \tValidation Loss: 0.8158\n",
      "Specificity: 0.998826 \tSensitivity: 0.194096 \tF2_score: 0.257746 \tDSC: 0.255704\n",
      "=== Epoch #12 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 12/51 [34:26<1:50:48, 170.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.6704 \tValidation Loss: 0.8292\n",
      "Specificity: 0.998750 \tSensitivity: 0.187982 \tF2_score: 0.174979 \tDSC: 0.164391\n",
      "=== Epoch #13 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 13/51 [37:17<1:47:56, 170.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.6160 \tValidation Loss: 0.8077\n",
      "Specificity: 0.998609 \tSensitivity: 0.209246 \tF2_score: 0.196352 \tDSC: 0.188593\n",
      "=== Epoch #14 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 14/51 [40:06<1:44:57, 170.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.6422 \tValidation Loss: 0.8203\n",
      "Specificity: 0.996855 \tSensitivity: 0.252198 \tF2_score: 0.196857 \tDSC: 0.155983\n",
      "=== Epoch #15 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 15/51 [42:56<1:42:05, 170.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.6426 \tValidation Loss: 0.8260\n",
      "Specificity: 0.998838 \tSensitivity: 0.177896 \tF2_score: 0.246561 \tDSC: 0.246211\n",
      "=== Epoch #16 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 16/51 [45:46<1:39:12, 170.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.6366 \tValidation Loss: 0.7959\n",
      "Specificity: 0.998161 \tSensitivity: 0.235297 \tF2_score: 0.283947 \tDSC: 0.263874\n",
      "=== Epoch #17 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 17/51 [48:38<1:36:40, 170.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.6299 \tValidation Loss: 0.7579\n",
      "Specificity: 0.997190 \tSensitivity: 0.324114 \tF2_score: 0.262441 \tDSC: 0.215632\n",
      "=== Epoch #18 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n",
      "Epoch: 18 \tTraining Loss: 0.6033 \tValidation Loss: 0.7605\n",
      "Specificity: 0.998292 \tSensitivity: 0.272938 \tF2_score: 0.319934 \tDSC: 0.300590\n",
      "Validation DSC increased.  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/51 [51:29<1:33:48, 170.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch #19 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/51 [54:21<1:31:16, 171.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.6519 \tValidation Loss: 0.8213\n",
      "Specificity: 0.997731 \tSensitivity: 0.220848 \tF2_score: 0.189994 \tDSC: 0.162926\n",
      "=== Epoch #20 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 20/51 [57:14<1:28:40, 171.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 0.6438 \tValidation Loss: 0.7904\n",
      "Specificity: 0.998468 \tSensitivity: 0.235529 \tF2_score: 0.287770 \tDSC: 0.272197\n",
      "=== Epoch #21 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/51 [1:00:05<1:25:45, 171.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 \tTraining Loss: 0.6269 \tValidation Loss: 0.8104\n",
      "Specificity: 0.998580 \tSensitivity: 0.211913 \tF2_score: 0.266023 \tDSC: 0.256529\n",
      "=== Epoch #22 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/51 [1:02:55<1:22:38, 170.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 \tTraining Loss: 0.5997 \tValidation Loss: 0.8204\n",
      "Specificity: 0.998729 \tSensitivity: 0.195163 \tF2_score: 0.254733 \tDSC: 0.247301\n",
      "=== Epoch #23 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/51 [1:05:49<1:20:13, 171.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 \tTraining Loss: 0.6157 \tValidation Loss: 0.8262\n",
      "Specificity: 0.998622 \tSensitivity: 0.187877 \tF2_score: 0.248756 \tDSC: 0.240674\n",
      "=== Epoch #24 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 24/51 [1:08:36<1:16:44, 170.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 \tTraining Loss: 0.6038 \tValidation Loss: 0.8599\n",
      "Specificity: 0.998757 \tSensitivity: 0.140982 \tF2_score: 0.210924 \tDSC: 0.215647\n",
      "=== Epoch #25 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n",
      "101 / 112...\n",
      "=== Validation ===\n",
      "1 / 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25/51 [1:11:26<1:13:44, 170.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 \tTraining Loss: 0.6148 \tValidation Loss: 0.7972\n",
      "Specificity: 0.998019 \tSensitivity: 0.233217 \tF2_score: 0.281167 \tDSC: 0.266601\n",
      "=== Epoch #26 ===\n",
      "=== Training ===\n",
      "1 / 112...\n",
      "51 / 112...\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®ä¿å­˜è·¯å¾„\n",
    "results_dir = 'results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M\")\n",
    "experiment_name = f\"run_{timestamp}\"\n",
    "model_save_path = os.path.join(results_dir, f\"{experiment_name}_model.pt\")\n",
    "loss_plot_path = os.path.join(results_dir, f\"{experiment_name}_loss_curve.png\")\n",
    "metric_save_path = os.path.join(results_dir, f\"{experiment_name}_metrics.csv\")\n",
    "result_save_path = os.path.join(results_dir, f\"{experiment_name}_inference_results.csv\")\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ: {experiment_name}\")\n",
    "\n",
    "if not CONFIG['inference_only']:\n",
    "    model = train_3D(CONFIG['n_epochs'], loaders, model, optimizer, criterion, \n",
    "                     CONFIG['train_on_gpu'], performance_metrics, model_save_path, 0.5)\n",
    "    \n",
    "    # è®­ç»ƒç»“æŸåå¤„ç†æ•°æ®\n",
    "    if os.path.exists('performance_metrics.csv'):\n",
    "        df = pd.read_csv('performance_metrics.csv')\n",
    "        df.to_csv(metric_save_path, index=False)\n",
    "        \n",
    "        # ç›´æ¥åœ¨ Jupyter ä¸­ç”»å›¾\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df['epoch'], df['Training Loss'], label='Train')\n",
    "        plt.plot(df['epoch'], df['Validation Loss'], label='Valid')\n",
    "        plt.legend()\n",
    "        plt.title(f'Training Process ({experiment_name})')\n",
    "        plt.show() # ç›´æ¥æ˜¾ç¤º\n",
    "        \n",
    "        plt.savefig(loss_plot_path)\n",
    "        print(\"è®­ç»ƒå®Œæˆã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb68c7-72dd-45e6-bc2e-38d955ee43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- å¼€å§‹æµ‹è¯•é›†è¯„ä¼° ---\")\n",
    "# åŠ è½½åˆšåˆšè®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨æŒ‡å®šå…¶ä»–è·¯å¾„ï¼‰\n",
    "best_model_path = model_save_path \n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"åŠ è½½æ¨¡å‹æƒé‡: {best_model_path}...\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"æ­£åœ¨æµ‹è¯• {len(part['test'])} ä¸ªæµ‹è¯•é›†ç—…ä¾‹...\")\n",
    "    df_test = get_inference_performance_metrics_3D(model, part['test'], Pancreas_3D_dataset, \n",
    "                                                  CONFIG['batch_size'], CONFIG['train_on_gpu'], \n",
    "                                                  0.5, kw, kh, kc, dw, dh, dc)\n",
    "    print(\"\\nğŸ“Š æµ‹è¯•é›†ç»“æœç»Ÿè®¡:\")\n",
    "    display(df_test.describe()) # Jupyter ç‰¹æœ‰çš„æ¼‚äº®è¡¨æ ¼æ˜¾ç¤º\n",
    "    \n",
    "    df_test.to_csv(result_save_path, index=False)\n",
    "    print(f\"âœ… è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_save_path}\")\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
